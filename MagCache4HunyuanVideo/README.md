<!-- ## **MagCache4HunyuanVideo** -->
# MagCache4HunyuanVideo

[MagCache](https://github.com/Zehong-Ma/MagCache) can speedup [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) 2.8x without much visual quality degradation, in a training-free manner. The following video shows the results generated by MagCache-HunyuanVideo.

<div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 10px; place-items: center; font-size: 1.0em;">
        <div style="text-align: center;">HunyuanVideo T2V (54min05s)</div>
        <div style="text-align: center;">TeaCache (23min49s) <br> PSNR: 22.80, 2.3x speedup</div>
        <div style="text-align: center;">MagCache (19min33s) <br> PSNR: 26.76, <b>2.8x</b> speedup</div>
      </div>
      <video class="video" autoplay controls muted loop playsinline>
        <source src="./static/videos/HunyuanVideo_t2v_two_astronauts_three_col.mp4" type="video/mp4">
      </video>
      <span style="font-size: 1.5em; width: 100%; display: inline-block; text-align: center;">HunyuanVideo T2V, 5s, 720P.</span>
      <br>
      <br>
      <br>
      <div style="display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; place-items: center; font-size: 1.0em;">
        <div style="text-align: center;">HunyuanVideo T2V (20min10s)</div>
        <div style="text-align: center;">TeaCache (8min53s) <br> PSNR: 23.10, 2.3x speedup</div>
        <div style="text-align: center;">MagCache (8min50s) <br> PSNR: 31.48, 2.3x speedup</div>
        <div style="text-align: center;">MagCache (7min17s) <br> PSNR: 29.22, <b>2.8x</b> speedup</div>
      </div>
      <video class="video" autoplay controls muted loop playsinline>
        <source src="../docs/static/videos/HunyuanVideo_t2v_a_couple_four.mp4" type="video/mp4">
      </video>
      <span style="font-size: 1.5em; width: 100%; display: inline-block; text-align: center;">HunyuanVideo T2V, 5s, 540P.</span>
      <br>
      <br>
      <br>
<video src="../docs/static/videos/HunyuanVideo_t2v_a_couple_four.mp4" controls controls style="width:100%; max-width:600px;"></video>
<video src="../docs/static/videos/HunyuanVideo_t2v_two_astronauts.mp4" controls controls style="width:100%; max-width:600px;"></video>

## ðŸ“ˆ Inference Latency Comparisons on a Single A800 GPU


|      Resolution       |        HunyuanVideo       |    TeaCache (0.15)   |  MagCache (E012K04R02) | MagCache (E024K06R02)  |
|:---------------------:|:-------------------------:|:--------------------:|:----------------------:|:----------------------:|
|         540p          |        ~20min10s          |     ~8min53s         |         ~8min50s       |          ~7min17s      |
|         720p          |        ~54min05s          |    ~23 min 49s       |        ~23min50s       |      ~19min33s         |


## Usage

Follow [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) to clone the repo and finish the installation, then copy 'magcache_sample_video.py' in this repo to the HunyuanVideo repo. You can modify the '`magcache_thresh`', '`magcache_K`', and '`retention_ratio`' in lines 294-296 to obtain your desired trade-off between latency and visul quality.

For single-gpu inference, you can use the following command:

```bash
cd HunyuanVideo

# 480P T2V
python3 magcache_sample_video.py \
    --video-size 544 960 \
    --video-length 129 \
    --infer-steps 50 \
    --seed 0 \
    --prompt "A couple in formal evening attire is caught in heavy rain on their way home, holding a black umbrella. In the flat shot, the man is wearing a black suit and the woman is wearing a white long dress. They walk slowly in the rain, and the rain drips down the umbrella. The camera moves smoothly with their steps, showing their elegant posture in the rain." \
    --flow-reverse \
    --use-cpu-offload \
    --save-path ./magcache_results

# 720P T2V
python3 magcache_sample_video.py \
    --video-size 720 1280 \
    --video-length 129 \
    --infer-steps 50 \
    --seed 0 \
    --prompt "The video shows two astronauts in bulky suits walking slowly on the moonâ€™s surface, against a vast starry universe. Their steps are heavy and slow, kicking up dust in the low-gravity environment. The scene is silent, mysterious, and evokes the courage and dreams of space exploration." \
    --flow-reverse \
    --use-cpu-offload \
    --save-path ./magcache_results

```

To generate a video with 8 GPUs, you can use the following command:

```bash
cd HunyuanVideo

torchrun --nproc_per_node=8 magcache_sample_video.py \
    --video-size 1280 720 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --flow-reverse \
    --seed 42 \
    --ulysses-degree 8 \
    --ring-degree 1 \
    --save-path ./teacache_results
```

For FP8 inference, you must explicitly specify the FP8 weight path. For example, to generate a video with fp8 weights, you can use the following command:

```bash
cd HunyuanVideo

DIT_CKPT_PATH={PATH_TO_FP8_WEIGHTS}/{WEIGHT_NAME}_fp8.pt

python3 magcache_sample_video.py \
    --dit-weight ${DIT_CKPT_PATH} \
    --video-size 1280 720 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --seed 42 \
    --embedded-cfg-scale 6.0 \
    --flow-shift 7.0 \
    --flow-reverse \
    --use-cpu-offload \
    --use-fp8 \
    --save-path ./teacache_fp8_results
```

## Citation
If you find MagCache is useful in your research or applications, please consider giving us a star ðŸŒŸ and citing it by the following BibTeX entry.

<!-- ```
@article{liu2024timestep,
  title={Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model},
  author={Liu, Feng and Zhang, Shiwei and Wang, Xiaofeng and Wei, Yujie and Qiu, Haonan and Zhao, Yuzhong and Zhang, Yingya and Ye, Qixiang and Wan, Fang},
  journal={arXiv preprint arXiv:2411.19108},
  year={2024}
}
``` -->


## Acknowledgements

We would like to thank the contributors to the [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) and [TeaCache](https://github.com/ali-vilab/TeaCache).
