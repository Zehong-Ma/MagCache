<!-- ## **MagCache4HunyuanVideo** -->
# MagCache4HunyuanVideo

[MagCache](https://github.com/Zehong-Ma/MagCache) can speedup [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) 2.8x without much visual quality degradation, in a training-free manner. The following video shows the results generated by MagCache-HunyuanVideo.

<div align="center">
  <video src="https://github.com/user-attachments/assets/a815048a-b25b-4c4a-8742-6c19ab572fbb" width="100%" poster=""> </video>
</div>
<div class="content has-text-centered">
  <img src="../assets/Hunyuan_T2V_720P_header.jpg" style="width: 100%"><br>
</div>
<details style="width: 100%; margin: auto;">
<summary>Prompt: The video shows two astronauts in bulky suits walking slowly on the moonâ€™s surface....</summary>
The video shows two astronauts in bulky suits walking slowly on the moonâ€™s surface, against a vast starry universe. Their steps are heavy and slow, kicking up dust in the low-gravity environment. The scene is silent, mysterious, and evokes the courage and dreams of space exploration.
</details>

## ðŸ“ˆ Inference Latency Comparisons on a Single A800 GPU


|      Resolution       |        HunyuanVideo       |    TeaCache (0.15)   |  MagCache (E012K04R02) | MagCache (E024K06R02)  |
|:---------------------:|:-------------------------:|:--------------------:|:----------------------:|:----------------------:|
|         540p          |        ~20min10s          |     ~8min53s         |         ~8min50s       |          ~7min17s      |
|         720p          |        ~54min05s          |    ~23 min 49s       |        ~23min50s       |      ~19min33s         |


## Usage

Follow [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) to clone the repo and finish the installation, then copy 'magcache_sample_video.py' in this repo to the HunyuanVideo repo. You can modify the '`magcache_thresh`', '`magcache_K`', and '`retention_ratio`' in lines 294-296 to obtain your desired trade-off between latency and visul quality.

For single-gpu inference, you can use the following command:

```bash
cd HunyuanVideo

# 480P T2V
python3 magcache_sample_video.py \
    --video-size 544 960 \
    --video-length 129 \
    --infer-steps 50 \
    --seed 0 \
    --prompt "A couple in formal evening attire is caught in heavy rain on their way home, holding a black umbrella. In the flat shot, the man is wearing a black suit and the woman is wearing a white long dress. They walk slowly in the rain, and the rain drips down the umbrella. The camera moves smoothly with their steps, showing their elegant posture in the rain." \
    --flow-reverse \
    --use-cpu-offload \
    --save-path ./magcache_results

# 720P T2V
python3 magcache_sample_video.py \
    --video-size 720 1280 \
    --video-length 129 \
    --infer-steps 50 \
    --seed 0 \
    --prompt "The video shows two astronauts in bulky suits walking slowly on the moonâ€™s surface, against a vast starry universe. Their steps are heavy and slow, kicking up dust in the low-gravity environment. The scene is silent, mysterious, and evokes the courage and dreams of space exploration." \
    --flow-reverse \
    --use-cpu-offload \
    --save-path ./magcache_results

```

To generate a video with 8 GPUs, you can use the following command:

```bash
cd HunyuanVideo

torchrun --nproc_per_node=8 magcache_sample_video.py \
    --video-size 1280 720 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --flow-reverse \
    --seed 42 \
    --ulysses-degree 8 \
    --ring-degree 1 \
    --save-path ./teacache_results
```

For FP8 inference, you must explicitly specify the FP8 weight path. For example, to generate a video with fp8 weights, you can use the following command:

```bash
cd HunyuanVideo

DIT_CKPT_PATH={PATH_TO_FP8_WEIGHTS}/{WEIGHT_NAME}_fp8.pt

python3 magcache_sample_video.py \
    --dit-weight ${DIT_CKPT_PATH} \
    --video-size 1280 720 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --seed 42 \
    --embedded-cfg-scale 6.0 \
    --flow-shift 7.0 \
    --flow-reverse \
    --use-cpu-offload \
    --use-fp8 \
    --save-path ./teacache_fp8_results
```

## Citation
If you find MagCache is useful in your research or applications, please consider giving us a star ðŸŒŸ and citing it by the following BibTeX entry.

<!-- ```
@article{liu2024timestep,
  title={Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model},
  author={Liu, Feng and Zhang, Shiwei and Wang, Xiaofeng and Wei, Yujie and Qiu, Haonan and Zhao, Yuzhong and Zhang, Yingya and Ye, Qixiang and Wan, Fang},
  journal={arXiv preprint arXiv:2411.19108},
  year={2024}
}
``` -->


## Acknowledgements

We would like to thank the contributors to the [HunyuanVideo](https://github.com/Tencent/HunyuanVideo) and [TeaCache](https://github.com/ali-vilab/TeaCache).
